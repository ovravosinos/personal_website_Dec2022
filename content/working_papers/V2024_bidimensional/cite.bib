@inproceedings{vravosinos2025_multidimensional,
author = {Vravosinos, Orestis},
title = {Multidimensional screening of strategic candidates},
year = {2025},
isbn = {9798400719431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3736252.3742541},
doi = {10.1145/3736252.3742541},
abstract = {This paper proposes a novel model of multidimensional screening, where a candidate (she) with two attributes—training and talent—chooses how much hard evidence of training to present. Then, the evaluator (he) possibly verifies at a cost the value of a composite measure of the candidate's training and talent before deciding whether to accept or reject the candidate. The candidate cannot unilaterally provide evidence of talent. The composite measure is increasing in both training and talent, and the evaluator (weakly) values both training and talent in the candidate. If the evaluator is going to verify the value of the composite measure, the candidate may have incentives to withhold evidence of training—although the evaluator values training—to influence how the evaluator interprets the composite measure. Particularly, she may want to withhold evidence of training to make the evaluator attribute the composite measure to talent instead, thereby overestimating her talent.This problem arises when the composite measure is less sensitive to talent than talent is valuable to the evaluator. In that case, the optimal evaluation scheme never combines evidence and verification in the evaluation of a certain candidate. Rather, it asks for evidence of training only to accept a high-training candidate without verification. The optimal mechanism favors high- over low-training candidates: (i) It accepts some high-training candidates—including unworthy ones—without verifying their composite measure but rather only by asking them for a certain level of evidence of training; and (ii) among candidates who do not meet that level of evidence, (iia) it accepts (after verification) some unworthy candidates with high training but low talent while (iib) rejecting some worthy candidates with high talent but low training.Remarkably, this is the structure of the optimal mechanism even when the evaluator only values talent. The evaluator still optimally favors high-training candidates even though training is worthless to him. He does so because of two forces: (i) to save on verification costs by accepting high-training candidates without verifying their composite measure and (ii) due to the strategic incentives of candidates to withhold evidence of training when the evaluator verifies the value of a composite measure that is under-sensitive to talent. The two forces are complements in inducing errors in favor of high- and against low-evidence candidates. Namely, the second force exacerbates the errors due to the verification cost by decreasing the effectiveness of verification, thereby pushing the evaluator to accept high-training candidates without verifying their composite measure to save on verification costs.The full paper is available at: https://orestisvravosinos.netlify.app/uploads/JMP_Orestis_Vravosinos.pdf},
booktitle = {Proceedings of the 26th ACM Conference on Economics and Computation},
pages = {345–346},
numpages = {2},
keywords = {multidimensional screening, persuasion game, evidence game, costly verification, verifiable disclosure, signal-jamming, costly lying, signal manipulation},
location = {Stanford University, Stanford, CA, USA},
series = {EC '25}
}

  
